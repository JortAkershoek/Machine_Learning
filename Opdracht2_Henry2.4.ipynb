{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8eb0ffd",
   "metadata": {},
   "source": [
    "# Machine Learning Portfolio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.fft import fft, ifft\n",
    "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2bf86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\", parse_dates=['date_hour'])\n",
    "df_test = pd.read_csv(\"test.csv\", parse_dates=['date_hour'])\n",
    "sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class date_time_features:\n",
    "    def __init__(self, data):\n",
    "        self.dfh = data.set_index('date_hour')\n",
    "        self.dfh = self.dfh.reset_index()\n",
    "        self.dfh[\"Year\"] = self.dfh[\"date_hour\"].dt.year\n",
    "        self.dfh[\"Month\"] = self.dfh[\"date_hour\"].dt.month\n",
    "        self.dfh[\"Day_of_Week\"] = self.dfh[\"date_hour\"].dt.dayofweek\n",
    "        self.dfh[\"Day_name\"] = self.dfh[\"date_hour\"].dt.day_name()\n",
    "        self.dfh[\"Hour\"] = self.dfh[\"date_hour\"].dt.hour\n",
    "        self.dfh[\"Week\"] = self.dfh[\"date_hour\"].dt.isocalendar().week\n",
    "        self.dfh.set_index('date_hour', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487a40f",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96e23e",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa903964",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = date_time_features(data=df_train)\n",
    "display(train.dfh.info(), train.dfh.describe(), train.dfh.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254c753",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = date_time_features(data=df_test)\n",
    "display(test.dfh.info(), test.dfh.describe(), test.dfh.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a013488",
   "metadata": {},
   "source": [
    "- date_hour: Je hebt informatie over de periode van 1-1-2011 t/m 30-11-2012\n",
    "- holiday: Vakantiedag of geen vakantiedag\n",
    "- weathersit: Weersituatie:\n",
    "    1. Helder, licht bewolkt, deels bewolkt\n",
    "    2. Mistig , mistig en licht bewolkt\n",
    "    3. Lichte sneeuw, lichte regen, lichte regen en onweer, zwaar bewolkt, lichte regen en zwaar bewolkt\n",
    "    4. Zware regen, hagel, zware mist, sneeuw.\n",
    "- temp: genormaliseerde temperatuur\n",
    "- atemp: genormaliseerde gevoelstemperatuur\n",
    "- hum: genormaliseerde luchtvochtigheid\n",
    "- windspeed: genormaliseerde windsnelheid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f422928",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = [\"holiday\",\"weathersit\"]\n",
    "for x in x_col:\n",
    "    sns.barplot(data=train.dfh, x=x, y=\"cnt\", estimator=np.mean, ci=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e125c",
   "metadata": {},
   "source": [
    "Voor holidays tegen verhuur aantal, zien we dat op gemiddelijk niet verschil heeft. Dus holidays is niet van belang of het product meer of minder verhuurd wordt.  \n",
    "Terwijl voor het situatie van het weer, zien we dat hoe slechter het weer is hoe minder er verhuurd wordt. Dus het weer is wel van belang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca102",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = [\"temp\", \"atemp\", \"hum\", \"windspeed\"]\n",
    "\n",
    "for x in x_col:\n",
    "    sns.lineplot(data=train.dfh, x=x, y=\"cnt\", estimator=np.mean)\n",
    "    plt.title(\"Average Rent Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf41d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=train.dfh, x=\"Hour\", y=\"cnt\", estimator=np.mean)\n",
    "plt.title(\"Average Rent Count\")\n",
    "plt.xlabel(\"Hour of the Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=train.dfh, x=\"Day_of_Week\", y=\"cnt\", estimator=np.mean)\n",
    "plt.title(\"Average Rent Count\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=train.dfh, x=\"Week\", y=\"cnt\", estimator=np.mean)\n",
    "plt.title(\"Average Rent Count\")\n",
    "plt.xlabel(\"Week of the Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c5ff8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=train.dfh, x=\"Month\", y=\"cnt\", estimator=np.mean)\n",
    "plt.title(\"Average Rent Count\")\n",
    "plt.xlabel(\"Month of the Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0a429",
   "metadata": {},
   "source": [
    "Uitleg uit de grafieken. Wat haal je eruit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e265c1c",
   "metadata": {},
   "source": [
    "## Timeseries Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b37390",
   "metadata": {},
   "source": [
    "### FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ebaa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tijdreeks = train.dfh['cnt']\n",
    "n = len(tijdreeks)\n",
    "freq = np.fft.fftfreq(n,1)\n",
    "fft_result = fft(tijdreeks)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(freq, np.abs(fft_result))\n",
    "plt.xlabel('Frequency (1/hour)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlim([0,0.05])\n",
    "plt.ylim([0,1e6])\n",
    "plt.title('Periodigram')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b17998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fft = pd.DataFrame(np.abs(fft_result))\n",
    "df_fft['freq'] = freq\n",
    "hours = []\n",
    "days= []\n",
    "for f in freq:\n",
    "    if f != 0:\n",
    "        hours.append(1/f)\n",
    "        days.append(1/f/24)\n",
    "    else:\n",
    "        hours.append(np.inf)\n",
    "        days.append(np.inf)\n",
    "df_fft['duur in uren'] = hours\n",
    "df_fft['duur in dagen'] = days\n",
    "df_fft.rename(columns={0:'amplitude'}, inplace=True)\n",
    "df_fft = df_fft[(df_fft['amplitude'] > 0.4e+06)&(df_fft['freq'] > 0)]\n",
    "df_fft\n",
    "\n",
    "# dagelijks patroon en jaarlijks patroon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317f6ec",
   "metadata": {},
   "source": [
    "### Lags & Multistep Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43724feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(ts, lags):\n",
    "    return pd.concat(\n",
    "        {\n",
    "            f'y_lag_{i}': ts.shift(i)\n",
    "            for i in range(1, lags + 1)\n",
    "        },\n",
    "        axis=1)\n",
    "\n",
    "def lagplot(x, y=None, lag=1, standardize=False, ax=None, **kwargs):\n",
    "    from matplotlib.offsetbox import AnchoredText\n",
    "    x_ = x.shift(lag)\n",
    "    if standardize:\n",
    "        x_ = (x_ - x_.mean()) / x_.std()\n",
    "    if y is not None:\n",
    "        y_ = (y - y.mean()) / y.std() if standardize else y\n",
    "    else:\n",
    "        y_ = x\n",
    "    corr = y_.corr(x_)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    scatter_kws = dict(\n",
    "        alpha=0.75,\n",
    "        s=3,\n",
    "    )\n",
    "    line_kws = dict(color='C3', )\n",
    "    ax = sns.regplot(x=x_,\n",
    "                     y=y_,\n",
    "                     scatter_kws=scatter_kws,\n",
    "                     line_kws=line_kws,\n",
    "                     lowess=True,\n",
    "                     ax=ax,\n",
    "                     **kwargs)\n",
    "    at = AnchoredText(\n",
    "        f\"{corr:.2f}\",\n",
    "        prop=dict(size=\"large\"),\n",
    "        frameon=True,\n",
    "        loc=\"upper left\",\n",
    "    )\n",
    "    at.patch.set_boxstyle(\"square, pad=0.0\")\n",
    "    ax.add_artist(at)\n",
    "    ax.set(title=f\"Lag {lag}\", xlabel=x_.name, ylabel=y_.name)\n",
    "    return ax\n",
    "\n",
    "def plot_lags(x, y=None, lags=6, nrows=1, lagplot_kwargs={}, **kwargs):\n",
    "    import math\n",
    "    kwargs.setdefault('nrows', nrows)\n",
    "    kwargs.setdefault('ncols', math.ceil(lags / nrows))\n",
    "    kwargs.setdefault('figsize', (kwargs['ncols'] * 2, nrows * 2 + 0.5))\n",
    "    fig, axs = plt.subplots(sharex=True, sharey=True, squeeze=False, **kwargs)\n",
    "    for ax, k in zip(fig.get_axes(), range(kwargs['nrows'] * kwargs['ncols'])):\n",
    "        if k + 1 <= lags:\n",
    "            ax = lagplot(x, y, lag=k + 1, ax=ax, **lagplot_kwargs)\n",
    "            ax.set_title(f\"Lag {k + 1}\", fontdict=dict(fontsize=14))\n",
    "            ax.set(xlabel=\"\", ylabel=\"\")\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    plt.setp(axs[-1, :], xlabel=x.name)\n",
    "    plt.setp(axs[:, 0], ylabel=y.name if y is not None else x.name)\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "    return fig\n",
    "\n",
    "def make_multistep_target(ts, steps):\n",
    "    return pd.concat(\n",
    "        {f'y_step_{i + 1}': ts.shift(-i)\n",
    "         for i in range(steps)},\n",
    "        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75348f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(train.dfh[\"cnt\"], lags=24)\n",
    "plt.ylim(-0.2,1)\n",
    "plot_pacf(train.dfh[\"cnt\"], lags=24, method=\"ywm\") # We zien de confidence intervals niet duidelijk.\n",
    "plot_pacf(train.dfh[\"cnt\"], lags=24, method=\"ywm\")\n",
    "plt.ylim(-0.15, 0.15)\n",
    "plt.title(\"Partial Autocorrelation Zoomed In\")\n",
    "plot_lags(train.dfh[\"cnt\"], lags=24, nrows=4)\n",
    "plt.show()\n",
    "\n",
    "# Lag 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46dfdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "sd = seasonal_decompose(train.dfh['cnt'], model='additive', period=24)\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.title(\"Trend\")\n",
    "sd.trend.plot()\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.title(\"Seasonal\")\n",
    "sd.seasonal.plot()\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.title(\"Resid\")\n",
    "sd.resid.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa28c3",
   "metadata": {},
   "source": [
    "We hebben een dagelijkse patroon, dus we kiezen 24 voor period (data in uren).  \n",
    "Op het trend grafiek, van het begin van 2011 stijgt het tot in de zomer en vanaf oktober 2011 daalt het weer tot nieuw jaar. In 2012 begint het ook met een stijging, dit stijgt tot rond april 2012 en vanaf oktober daalt het ook tot nieuwe jaar.  \n",
    "Het product is trending in lente en zomer.  \n",
    "De seasonal grafiek ziet er bijna een hele blok uit, het patroon geeft aan dat het een herhalend dagelijkse cyclus is. \n",
    "Uit de resid grafiek zie je hoe groot de storingen zijn in de data die niet in de trend en seasonal zitten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc38686",
   "metadata": {},
   "source": [
    "### Timeseries Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42fb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns has to be numeric. Make dummies or drop them.\n",
    "df = pd.get_dummies(train.dfh, \"Day_name\")\n",
    "X_train = df.drop(\"cnt\", axis=1)\n",
    "y_train = df[\"cnt\"]\n",
    "X_test = pd.get_dummies(test.dfh, \"Day_name\")\n",
    "\n",
    "\n",
    "# Create fourier\n",
    "# We saw that there is a Yearly and Daily pattern.\n",
    "# There are other peaks very close to the Daily frequency, we'll test with different orders.\n",
    "fourier = CalendarFourier(freq='A', order = 1) # A-Annual\n",
    "fourier2 = CalendarFourier(freq='D', order = 1) # D-Daily\n",
    "\n",
    "dp = DeterministicProcess(index=X_train.index, constant=False, order=1, seasonal=False,\n",
    "                          additional_terms = [fourier, fourier2], drop = True)\n",
    "X_train2 = dp.in_sample()\n",
    "X_test2 = dp.out_of_sample(steps = len(X_test),forecast_index=X_test.index)\n",
    "\n",
    "X_train = pd.concat([X_train, X_train2], axis=1)\n",
    "X_test = pd.concat([X_test, X_test2], axis=1)\n",
    "display(X_train.head(), X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15822f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_lags(X_train, lags=5)\n",
    "X.fillna(0.0, inplace=True)\n",
    "\n",
    "test = make_lags(X_test, lags=5)\n",
    "test.fillna(0.0, inplace=True)\n",
    "\n",
    "y = make_multistep_target(y_train, steps=7*24).dropna()\n",
    "\n",
    "y, X = y.align(X, join='inner', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2511e371",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# order = (5,1,0)\n",
    "\n",
    "# # Fit the ARIMA model\n",
    "# model = ARIMA(X, order=order)\n",
    "# fitted_model = model.fit()\n",
    "\n",
    "# # Forecast using the fitted model\n",
    "# forecast, stderr, conf_int = fitted_model.forecast(steps=len(test))\n",
    "\n",
    "# # Visualize the results\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(X.index, X, label='Train')\n",
    "# plt.plot(test.index, test, label='Test')\n",
    "# plt.plot(test.index, forecast, label='Forecast', color='red')\n",
    "# plt.legend()\n",
    "# plt.title('ARIMA Forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc19e7d",
   "metadata": {},
   "source": [
    "## Modelleren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3143d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(X.head(), y.head(), test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446317f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"lr\": {\n",
    "        \"model\":LinearRegression(),\n",
    "        \"params\":{}\n",
    "    },\n",
    "    \"dt\": {\n",
    "        \"model\":DecisionTreeRegressor(), \n",
    "        \"params\":{\n",
    "            \"criterion\":[\"squared_error\",\"friedman_mse\",\"absolute_error\",\"poisson\"],\n",
    "            \"splitter\":[\"best\", \"random\"],\n",
    "            \"max_depth\":[None,30,35]\n",
    "        }\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"model\":RandomForestRegressor(random_state=42, n_jobs=-1), \n",
    "        \"params\":{\"criterion\":[\"squared_error\",\"friedman_mse\",\"absolute_error\",\"poisson\"],\n",
    "                  \"max_depth\": [None,30,35]}\n",
    "    },\n",
    "    \"gb\": {\n",
    "        \"model\":GradientBoostingRegressor(random_state=42), \n",
    "        \"params\":{\"loss\":[\"squared_error\",\"absolute_error\",\"huber\",\"quantile\"],\n",
    "                  \"criterion\":[\"squared_error\",\"friedman_mse\"],\n",
    "                  \"max_depth\":[None,30,35],\n",
    "                  \"learning_rate\":[0.01,0.1,1.0]}\n",
    "    },\n",
    "    \"ada\": {\n",
    "        \"model\":AdaBoostRegressor(estimator=DecisionTreeRegressor()), \n",
    "        \"params\":{\"loss\":[\"linear\",\"square\",\"exponential\"],\n",
    "                  \"n_estimators\":[50,100,150],\n",
    "                  \"learning_rate\":[0.01, 0.1, 1.0],\n",
    "                  \"base_estimator__max_depth\":[None, 30, 35]}\n",
    "    }\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7feff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "best_params = {}\n",
    "best_scores = {}\n",
    "\n",
    "for model_name, config in models.items():\n",
    "    grid_search = GridSearchCV(config[\"model\"], config[\"params\"], cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    best_params[model_name] = grid_search.best_params_\n",
    "    \n",
    "    cross_val_scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    best_scores[model_name] = cross_val_scores.mean()\n",
    "    \n",
    "for model_name, best_model in best_models.items():\n",
    "    print(f\"Best model for {model_name}: {best_model}\")\n",
    "    print(f\"Best parameters for {model_name}: {best_params[model_name]}\")\n",
    "    print(f\"Cross-validation score for {model_name}: {best_scores[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bbd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybride model\n",
    "X_train_H, X_test_H, y_train_H, y_test_H = train_test_split(X, y, test_size=7*24, shuffle=False)\n",
    "\n",
    "# DeterministicProcess\n",
    "fourier = CalendarFourier(freq='A', order = 1) # A-Annual\n",
    "fourier2 = CalendarFourier(freq='D', order = 1) # D-Daily\n",
    "\n",
    "dp = DeterministicProcess(index=X_train_H.index, constant=False, order=1, seasonal=False,\n",
    "                          additional_terms = [fourier, fourier2], drop = True)\n",
    "X_train2_H = dp.in_sample()\n",
    "X_test2_H = dp.out_of_sample(steps = len(y_test_H),forecast_index=y_test_H.index)\n",
    "\n",
    "# Pick 2 models\n",
    "model1 = LinearRegression()\n",
    "model2 = DecisionTreeRegressor()\n",
    "\n",
    "model1.fit(X_train_H, y_train_H)\n",
    "train_predict1 = model1.predict(X_train_H)\n",
    "test_predict1 = model1.predict(X_test_H)\n",
    "\n",
    "y_train_res = y_train_H - train_predict1\n",
    "y_test_res = y_test_H - test_predict1\n",
    "\n",
    "model2.fit(X_train2_H, y_train_res)\n",
    "train_predictions_total = model2.predict(X_train2_H) + train_predict1\n",
    "test_predictions_total = model2.predict(X_test2_H) + test_predict1\n",
    "\n",
    "print('train r2', r2_score(y_train_H, train_predictions_total))\n",
    "print('test r2', r2_score(y_test_H, test_predictions_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a6087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
